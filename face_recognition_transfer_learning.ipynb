{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc2040d1",
   "metadata": {},
   "source": [
    "# Face Recognition Transfer Learning (CNN + ViT)\n",
    "\n",
    "Notebook ini disiapkan khusus untuk Google Colab guna memenuhi requirement pada `Tugas Besar Deep Learning.pdf`. Pipeline mencakup:\n",
    "\n",
    "- Download + ekstraksi dataset wajah dari Google Drive (gdown).\n",
    "- Preprocessing dan face alignment menggunakan DeepFace agar rasio wajah konsisten.\n",
    "- Transfer learning dua arsitektur: EfficientNet (CNN) & Vision Transformer (ViT) lengkap dengan fine-tuning dan regularisasi agresif.\n",
    "- Evaluasi komprehensif (classification report, confusion matrix) serta demo inference.\n",
    "\n",
    "Jalankan setiap sel secara berurutan di runtime GPU (A100 / T4) Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97ae082",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e905372",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -q --upgrade pip\n",
    "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip install -q deepface timm albumentations==1.4.8 scikit-learn gdown seaborn opencv-python pillow-heif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb5aedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import zipfile\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from uuid import uuid4\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "import timm\n",
    "from deepface import DeepFace\n",
    "import cv2\n",
    "import gdown\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from pillow_heif import register_heif_opener\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# ensure PIL can read HEIC/HEIF assets\n",
    "register_heif_opener()\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-colorblind\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "SEED = 1337\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "VAL_RATIO = 0.1\n",
    "TEST_RATIO = 0.1\n",
    "EXPECTED_CLASSES = 70\n",
    "\n",
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(SEED)\n",
    "\n",
    "DATA_DIR = Path(\"data_face_recognition\")\n",
    "RAW_DIR = DATA_DIR / \"dataset\"\n",
    "PREPARED_DIR = DATA_DIR / \"prepared_faces\"\n",
    "CHECKPOINT_DIR = Path(\"checkpoints\")\n",
    "for path in (DATA_DIR, RAW_DIR, PREPARED_DIR, CHECKPOINT_DIR):\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "FILE_ID = \"1tDo2zQC_1ZKY8aMYaalgr6nxRmBcRxaO\"\n",
    "DOWNLOAD_URL = f\"https://drive.google.com/uc?id={FILE_ID}\"\n",
    "ZIP_PATH = DATA_DIR / \"dataset.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87664a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_if_needed(root: Path):\n",
    "    children = [p for p in root.iterdir() if p.is_dir() and not p.name.startswith('.__')]\n",
    "    if len(children) == 1 and (children[0] / 'Train').exists():\n",
    "        inner = children[0]\n",
    "        print(f\"Menemukan folder tunggal {inner.name}, memindahkan isinya ke {root} ...\")\n",
    "        for item in inner.iterdir():\n",
    "            shutil.move(str(item), root / item.name)\n",
    "        shutil.rmtree(inner)\n",
    "\n",
    "def remove_macos_artifacts(root: Path):\n",
    "    removed_dirs = 0\n",
    "    for dir_path in root.glob('**/__MACOSX'):\n",
    "        shutil.rmtree(dir_path, ignore_errors=True)\n",
    "        removed_dirs += 1\n",
    "    if removed_dirs:\n",
    "        print(f\"Menghapus {removed_dirs} folder __MACOSX.\")\n",
    "\n",
    "def convert_all_to_jpg(root: Path):\n",
    "    convertible_exts = {'.jpeg', '.png', '.bmp', '.webp', '.tif', '.tiff', '.heic', '.heif'}\n",
    "    converted = 0\n",
    "    skipped = 0\n",
    "    for file_path in root.rglob('*'):\n",
    "        if file_path.is_dir():\n",
    "            continue\n",
    "        if file_path.name.startswith('._') or file_path.name in {'.DS_Store'}:\n",
    "            skipped += 1\n",
    "            continue\n",
    "        suffix = file_path.suffix.lower()\n",
    "        if suffix == '.jpg':\n",
    "            continue\n",
    "        if suffix not in convertible_exts:\n",
    "            continue\n",
    "        target_path = file_path.with_suffix('.jpg')\n",
    "        if target_path.exists():\n",
    "            target_path = target_path.with_name(f\"{target_path.stem}_{uuid4().hex[:6]}.jpg\")\n",
    "        try:\n",
    "            image = Image.open(file_path).convert('RGB')\n",
    "            image.save(target_path, format='JPEG', quality=95)\n",
    "            file_path.unlink()\n",
    "            converted += 1\n",
    "        except Exception as exc:\n",
    "            print(f\"[WARNING] gagal konversi {file_path}: {exc}\")\n",
    "    if converted:\n",
    "        print(f\"Konversi universal ke JPG selesai: {converted} file.\")\n",
    "    else:\n",
    "        print(\"Tidak ada file yang perlu dikonversi.\")\n",
    "    if skipped:\n",
    "        print(f\"Mengabaikan {skipped} file resource (.DS_Store / ._) dari MacOS.\")\n",
    "\n",
    "if not ZIP_PATH.exists():\n",
    "    print(\"Mengunduh dataset...\")\n",
    "    gdown.download(DOWNLOAD_URL, str(ZIP_PATH), quiet=False)\n",
    "else:\n",
    "    print(\"File ZIP sudah ada, skip download.\")\n",
    "\n",
    "if not any(RAW_DIR.iterdir()):\n",
    "    print(\"Mengekstrak dataset...\")\n",
    "    with zipfile.ZipFile(ZIP_PATH, 'r') as zf:\n",
    "        zf.extractall(RAW_DIR)\n",
    "else:\n",
    "    print(\"Dataset sudah diekstrak.\")\n",
    "\n",
    "flatten_if_needed(RAW_DIR)\n",
    "for sub in RAW_DIR.iterdir():\n",
    "    if sub.is_dir():\n",
    "        flatten_if_needed(sub)\n",
    "\n",
    "remove_macos_artifacts(RAW_DIR)\n",
    "convert_all_to_jpg(RAW_DIR)\n",
    "\n",
    "macos_dirs = list(RAW_DIR.rglob('_MacOs'))\n",
    "train_dir = RAW_DIR / 'Train'\n",
    "if macos_dirs and train_dir.exists():\n",
    "    for mac_dir in macos_dirs:\n",
    "        print(f\"Menggabungkan isi {mac_dir} ke {train_dir} ...\")\n",
    "        for class_dir in mac_dir.iterdir():\n",
    "            if not class_dir.is_dir():\n",
    "                continue\n",
    "            target_dir = train_dir / class_dir.name\n",
    "            target_dir.mkdir(parents=True, exist_ok=True)\n",
    "            for item in class_dir.glob('*'):\n",
    "                if item.is_dir():\n",
    "                    continue\n",
    "                if item.name.startswith('._') or item.name == '.DS_Store':\n",
    "                    continue\n",
    "                dest = target_dir / item.name\n",
    "                if dest.exists():\n",
    "                    dest = target_dir / f\"{item.stem}_mac{item.suffix}\"\n",
    "                shutil.move(str(item), dest)\n",
    "        shutil.rmtree(mac_dir)\n",
    "    print(\"Folder _MacOs selesai digabungkan.\")\n",
    "else:\n",
    "    print(\"Tidak menemukan folder _MacOs atau Train belum ada.\")\n",
    "\n",
    "print(\"Isi folder dataset (level 1):\")\n",
    "for path in RAW_DIR.iterdir():\n",
    "    print(' -', path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e437c76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_EXTS = {'.jpg'}\n",
    "\n",
    "def detect_split_dirs(source_root: Path):\n",
    "    candidates = [d for d in source_root.iterdir() if d.is_dir() and not d.name.startswith('.__')]\n",
    "    split_dirs = []\n",
    "    for cand in candidates:\n",
    "        if any(child.is_dir() for child in cand.iterdir()):\n",
    "            split_dirs.append(cand)\n",
    "    if not split_dirs:\n",
    "        split_dirs = [source_root]\n",
    "    return split_dirs\n",
    "\n",
    "def align_and_prepare(source_root: Path, target_root: Path, detector: str = 'retinaface', force: bool = False):\n",
    "    sample_exists = target_root.exists() and any(target_root.rglob('*.jpg'))\n",
    "    if sample_exists and not force:\n",
    "        print('Dataset ter-align sudah tersedia, skip langkah ini.')\n",
    "        return\n",
    "    target_root.mkdir(parents=True, exist_ok=True)\n",
    "    for split_dir in detect_split_dirs(source_root):\n",
    "        split_name = 'Train' if split_dir == source_root else split_dir.name\n",
    "        class_dirs = [d for d in split_dir.iterdir() if d.is_dir()]\n",
    "        for class_dir in class_dirs:\n",
    "            image_paths = [p for p in class_dir.rglob('*') if p.suffix.lower() in VALID_EXTS]\n",
    "            if not image_paths:\n",
    "                continue\n",
    "            dest_dir = target_root / split_name / class_dir.name\n",
    "            dest_dir.mkdir(parents=True, exist_ok=True)\n",
    "            for img_path in tqdm(image_paths, desc=f\"{split_name}-{class_dir.name}\", leave=False):\n",
    "                dest_path = dest_dir / f\"{img_path.stem}.jpg\"\n",
    "                if dest_path.exists():\n",
    "                    continue\n",
    "                try:\n",
    "                    faces = DeepFace.extract_faces(img_path=str(img_path), detector_backend=detector, enforce_detection=False)\n",
    "                    if not faces:\n",
    "                        shutil.copy(str(img_path), dest_path)\n",
    "                        continue\n",
    "                    face = faces[0]['face']\n",
    "                    if isinstance(face, np.ndarray) and face.max() <= 1.0:\n",
    "                        face = (face * 255).astype('uint8')\n",
    "                    face_bgr = cv2.cvtColor(face, cv2.COLOR_RGB2BGR)\n",
    "                    cv2.imwrite(str(dest_path), face_bgr)\n",
    "                except Exception as exc:\n",
    "                    print(f\"[WARNING] {img_path.name}: {exc}\")\n",
    "    print('Face alignment selesai, dataset siap digunakan.')\n",
    "\n",
    "align_and_prepare(RAW_DIR, PREPARED_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f216635d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceSubset(Dataset):\n",
    "    def __init__(self, base_dataset: datasets.ImageFolder, indices, transform):\n",
    "        self.base_dataset = base_dataset\n",
    "        self.indices = np.array(indices)\n",
    "        self.transform = transform\n",
    "        self.samples = [base_dataset.samples[i] for i in self.indices]\n",
    "        self.targets = [base_dataset.targets[i] for i in self.indices]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.samples[idx]\n",
    "        image = self.base_dataset.loader(path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "train_root = PREPARED_DIR / 'Train'\n",
    "if not train_root.exists():\n",
    "    raise FileNotFoundError('Folder Train tidak ditemukan setelah preprocessing. Pastikan struktur dataset benar.')\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE + 32, IMG_SIZE + 32)),\n",
    "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomApply([transforms.ColorJitter(0.15, 0.15, 0.15, 0.05)], p=0.3),\n",
    "    transforms.RandomApply([transforms.GaussianBlur(kernel_size=3)], p=0.2),\n",
    "    transforms.AutoAugment(transforms.AutoAugmentPolicy.IMAGENET),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    " ])\n",
    "\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    " ])\n",
    "\n",
    "base_dataset = datasets.ImageFolder(str(train_root))\n",
    "class_names = base_dataset.classes\n",
    "num_classes = len(class_names)\n",
    "print(f\"Total kelas: {num_classes} -> {class_names}\")\n",
    "if num_classes != EXPECTED_CLASSES:\n",
    "    raise ValueError(f\"Dataset memiliki {num_classes} kelas, namun requirement tugas meminta {EXPECTED_CLASSES} kelas. Pastikan struktur folder sudah lengkap sebelum training.\")\n",
    "num_classes = EXPECTED_CLASSES\n",
    "\n",
    "indices = np.arange(len(base_dataset))\n",
    "targets = np.array(base_dataset.targets)\n",
    "sss_primary = StratifiedShuffleSplit(n_splits=1, test_size=VAL_RATIO + TEST_RATIO, random_state=SEED)\n",
    "train_idx, valtest_idx = next(sss_primary.split(indices, targets))\n",
    "relative_test_ratio = TEST_RATIO / (VAL_RATIO + TEST_RATIO)\n",
    "sss_secondary = StratifiedShuffleSplit(n_splits=1, test_size=relative_test_ratio, random_state=SEED)\n",
    "val_rel_idx, test_rel_idx = next(sss_secondary.split(valtest_idx, targets[valtest_idx]))\n",
    "val_idx = valtest_idx[val_rel_idx]\n",
    "test_idx = valtest_idx[test_rel_idx]\n",
    "\n",
    "train_subset = FaceSubset(base_dataset, train_idx, train_transform)\n",
    "val_subset = FaceSubset(base_dataset, val_idx, eval_transform)\n",
    "internal_test_subset = FaceSubset(base_dataset, test_idx, eval_transform)\n",
    "\n",
    "external_test_root = PREPARED_DIR / 'Test'\n",
    "if external_test_root.exists() and any(external_test_root.iterdir()):\n",
    "    print('Menggunakan folder Test eksternal untuk evaluasi.')\n",
    "    test_dataset = datasets.ImageFolder(str(external_test_root), transform=eval_transform)\n",
    "    test_samples = [s[0] for s in test_dataset.samples]\n",
    "else:\n",
    "    print('Folder Test tidak tersedia, memakai split internal.')\n",
    "    test_dataset = internal_test_subset\n",
    "    test_samples = [s[0] for s in internal_test_subset.samples]\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "train_counts = np.bincount(train_subset.targets, minlength=len(class_names))\n",
    "class_weights = len(train_subset.targets) / (len(class_names) * torch.tensor(train_counts, dtype=torch.float32))\n",
    "CLASS_WEIGHTS = class_weights\n",
    "print('Distribusi kelas train:', train_counts)\n",
    "print('Class weights:', class_weights.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78bb4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_loader(model, data_loader, criterion):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    loss_sum = 0.0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs = inputs.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss_sum += loss.item() * inputs.size(0)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += inputs.size(0)\n",
    "    return loss_sum / total, correct / total\n",
    "\n",
    "def plot_history(history, title):\n",
    "    epochs = [h['epoch'] for h in history]\n",
    "    train_loss = [h['train_loss'] for h in history]\n",
    "    val_loss = [h['val_loss'] for h in history]\n",
    "    train_acc = [h['train_acc'] for h in history]\n",
    "    val_acc = [h['val_acc'] for h in history]\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(epochs, train_loss, label='Train')\n",
    "    plt.plot(epochs, val_loss, label='Val')\n",
    "    plt.title(f'{title} Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(epochs, train_acc, label='Train')\n",
    "    plt.plot(epochs, val_acc, label='Val')\n",
    "    plt.title(f'{title} Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def build_cnn_model(num_classes: int) -> nn.Module:\n",
    "    model = models.efficientnet_b4(weights=models.EfficientNet_B4_Weights.IMAGENET1K_V1)\n",
    "    for param in model.features.parameters():\n",
    "        param.requires_grad = False\n",
    "    in_features = model.classifier[1].in_features\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Dropout(0.45),\n",
    "        nn.Linear(in_features, 512),\n",
    "        nn.GELU(),\n",
    "        nn.BatchNorm1d(512),\n",
    "        nn.Dropout(0.25),\n",
    "        nn.Linear(512, num_classes)\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def build_vit_model(num_classes: int) -> nn.Module:\n",
    "    model = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=num_classes)\n",
    "    for name, param in model.named_parameters():\n",
    "        if not name.startswith('head'):\n",
    "            param.requires_grad = False\n",
    "    in_features = model.head.in_features\n",
    "    model.head = nn.Sequential(\n",
    "        nn.LayerNorm(in_features),\n",
    "        nn.Linear(in_features, num_classes)\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def train_model(model, train_loader, val_loader, *, epochs=15, lr=3e-4, weight_decay=1e-4, unfreeze_at=3, model_name='model'):\n",
    "    model = model.to(device)\n",
    "    history = []\n",
    "    best_acc = 0.0\n",
    "    best_path = CHECKPOINT_DIR / f\"{model_name}_best.pth\"\n",
    "    criterion = nn.CrossEntropyLoss(weight=CLASS_WEIGHTS.to(device), label_smoothing=0.1)\n",
    "    optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=device.type == 'cuda')\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        if unfreeze_at and epoch == unfreeze_at:\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = True\n",
    "            optimizer = torch.optim.AdamW(model.parameters(), lr=lr * 0.25, weight_decay=weight_decay / 2)\n",
    "            scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs - epoch + 1)\n",
    "            print(f\"[{model_name}] Backbone di-unfreeze pada epoch {epoch}.\")\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        total = 0\n",
    "        for inputs, labels in tqdm(train_loader, desc=f\"{model_name} Epoch {epoch}/{epochs}\", leave=False):\n",
    "            inputs = inputs.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            with torch.cuda.amp.autocast(enabled=device.type == 'cuda'):\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "            scaler.scale(loss).backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            train_correct += (preds == labels).sum().item()\n",
    "            total += inputs.size(0)\n",
    "        scheduler.step()\n",
    "        train_loss /= total\n",
    "        train_acc = train_correct / total\n",
    "        val_loss, val_acc = evaluate_on_loader(model, val_loader, criterion)\n",
    "        history.append({'epoch': epoch, 'train_loss': train_loss, 'train_acc': train_acc, 'val_loss': val_loss, 'val_acc': val_acc})\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save({'model_state': model.state_dict(), 'val_acc': val_acc, 'epoch': epoch}, best_path)\n",
    "            print(f\"[{model_name}] ðŸ”¥ val_acc meningkat ke {val_acc:.4f} (epoch {epoch}).\")\n",
    "        else:\n",
    "            print(f\"[{model_name}] val_acc {val_acc:.4f} | train_acc {train_acc:.4f}\")\n",
    "    return history, best_path\n",
    "\n",
    "def evaluate_checkpoint(build_fn, checkpoint_path, data_loader, class_names, title='Model'):\n",
    "    model = build_fn(len(class_names)).to(device)\n",
    "    state = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(state['model_state'])\n",
    "    model.eval()\n",
    "    preds, labels_list = [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(data_loader, desc=f\"Eval {title}\", leave=False):\n",
    "            inputs = inputs.to(device, non_blocking=True)\n",
    "            outputs = model(inputs)\n",
    "            preds.extend(outputs.argmax(dim=1).cpu().numpy())\n",
    "            labels_list.extend(labels.cpu().numpy())\n",
    "    acc = accuracy_score(labels_list, preds)\n",
    "    print(f\"{title} accuracy: {acc:.4f}\")\n",
    "    print(classification_report(labels_list, preds, target_names=class_names))\n",
    "    cm = confusion_matrix(labels_list, preds)\n",
    "    plt.figure(figsize=(6,5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(f\"{title} Confusion Matrix\")\n",
    "    plt.ylabel('True')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.show()\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76e980a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = build_cnn_model(num_classes)\n",
    "cnn_history, cnn_ckpt = train_model(\n",
    "    cnn_model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    epochs=18,\n",
    "    lr=3e-4,\n",
    "    weight_decay=1e-4,\n",
    "    unfreeze_at=4,\n",
    "    model_name='cnn_efficientnet'\n",
    ")\n",
    "plot_history(cnn_history, 'EfficientNet-B4 (CNN)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68bc150",
   "metadata": {},
   "outputs": [],
   "source": [
    "vit_model = build_vit_model(num_classes)\n",
    "vit_history, vit_ckpt = train_model(\n",
    "    vit_model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    epochs=22,\n",
    "    lr=2e-4,\n",
    "    weight_decay=5e-5,\n",
    "    unfreeze_at=6,\n",
    "    model_name='vit_base'\n",
    ")\n",
    "plot_history(vit_history, 'ViT-B/16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0725edb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Evaluasi EfficientNet-B4 pada set test:')\n",
    "            cnn_test_acc = evaluate_checkpoint(build_cnn_model, cnn_ckpt, test_loader, class_names, title='CNN EfficientNet-B4')\n",
    "            print('\n",
    "Evaluasi ViT-B/16 pada set test:')\n",
    "            vit_test_acc = evaluate_checkpoint(build_vit_model, vit_ckpt, test_loader, class_names, title='ViT-B/16')\n",
    "            print(f\"Ringkasan -> CNN: {cnn_test_acc:.4f} | ViT: {vit_test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefa4a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(model, image_path: str, transform):\n",
    "                image = Image.open(image_path).convert('RGB')\n",
    "                tensor = transform(image).unsqueeze(0).to(device)\n",
    "                with torch.no_grad():\n",
    "                    logits = model(tensor)\n",
    "                    probs = torch.softmax(logits, dim=1)[0].cpu().numpy()\n",
    "                pred_idx = probs.argmax()\n",
    "                return pred_idx, probs[pred_idx], probs\n",
    "\n",
    "            sample_paths = random.sample(test_samples, k=min(3, len(test_samples)))\n",
    "            print('Menampilkan prediksi untuk sampel:', sample_paths)\n",
    "\n",
    "            cnn_infer = build_cnn_model(num_classes).to(device)\n",
    "            cnn_infer.load_state_dict(torch.load(cnn_ckpt, map_location=device)['model_state'])\n",
    "            cnn_infer.eval()\n",
    "            vit_infer = build_vit_model(num_classes).to(device)\n",
    "            vit_infer.load_state_dict(torch.load(vit_ckpt, map_location=device)['model_state'])\n",
    "            vit_infer.eval()\n",
    "\n",
    "            for path in sample_paths:\n",
    "                label_name = Path(path).parent.name\n",
    "                cnn_idx, cnn_conf, cnn_probs = predict_image(cnn_infer, path, eval_transform)\n",
    "                vit_idx, vit_conf, vit_probs = predict_image(vit_infer, path, eval_transform)\n",
    "                print(f\"\n",
    "File: {path}\")\n",
    "                print(f\"Label GT : {label_name}\")\n",
    "                print(f\"CNN Pred : {class_names[cnn_idx]} ({cnn_conf:.3f})\")\n",
    "                print(f\"ViT Pred : {class_names[vit_idx]} ({vit_conf:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5ba3ff",
   "metadata": {},
   "source": [
    "## Catatan Pengembangan Lanjutan\n",
    "\n",
    "- Silakan aktifkan `force=True` pada fungsi `align_and_prepare` bila ingin re-build dataset setelah menambah gambar baru.\n",
    "- Tambahkan augmentasi spesifik (CutMix/MixUp) pada loader untuk menangani kelas dengan data sedikit.\n",
    "- Notebook ini menyimpan checkpoint terbaik di folder `checkpoints/`. Unggah ke Drive bila perlu inference di sesi berbeda.\n",
    "- Untuk deployment, export model menjadi TorchScript / ONNX atau buat pipeline embedding + ANN index menggunakan bobot terbaik."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
